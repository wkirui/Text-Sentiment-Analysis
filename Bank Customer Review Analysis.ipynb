{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Sentiment Analysis\n",
    "In this notebook I look at customer reviews for the top banks in Kenya. Is it enough to use social media comments to make an informed decision a given bank?\n",
    "I will be using data from Twitter in this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Access tokens\n",
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonpickle\n",
    "\n",
    "# get access\n",
    "# keys are stored in a '.env' file\n",
    "consumer_key = os.getenv('CONSUMER_KEY')\n",
    "consumer_secret= os.getenv('CONSUMER_SECRET')\n",
    "access_token =  os.getenv('ACCESS_TOKEN')\n",
    "access_secret =  os.getenv('ACCESS_SECRET')\n",
    "\n",
    "# authorize access\n",
    "oath = OAuthHandler(consumer_key,consumer_secret)\n",
    "oath.set_access_token(access_token,access_secret)\n",
    "\n",
    "#create api\n",
    "twitter_api = tweepy.API(oath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas is a data wrangling platform for #Python widely adopted in the scientific computing community. #pandas proviâ€¦ https://t.co/gLZT0aosPi\n",
      "The coronavirus pandemic is dramatically changing the way Americans eat https://t.co/V42RfU8qLz\n",
      "Burger King says its restaurants are awful (so use a delivery app) https://t.co/Jb04qDFeI2\n",
      "A shooting in Washington, D.C., early on Sunday morning left at least one person dead and 20 people wounded, the auâ€¦ https://t.co/vjZ7fuhwx9\n",
      "Sri Lankaâ€™s government is looking ever more like a family business https://t.co/SXjnMH4tt4\n",
      "With just a few clicks, you can send all those photos and videos youâ€™ve posted on Facebook to Google Photos.â€‹ https://t.co/KRKvancO1i\n",
      "RT @watson_makau: @wezlie22000 @MigunaMiguna @makaumutua A country's entire security and intelligence apparatus can't be terrified of a papâ€¦\n",
      "Warigi: Leadersâ€™ greed amid economic downturn would test the patience of the Good Lord https://t.co/399eHXPhbO\n",
      "A threat to water supplies across Asia.\n",
      "\n",
      "ðŸ“• Read more: https://t.co/OWV8jDbkTA https://t.co/1LMAKlnHYM\n",
      "In Raila, a treasure trove of faith and eternal optimism https://t.co/O3KKNUa9jv https://t.co/NwjAr9Gqhq\n"
     ]
    }
   ],
   "source": [
    "# examine top 10 tweets on timeline\n",
    "for tweet in tweepy.Cursor(twitter_api.home_timeline).items(10):\n",
    "    print(tweet.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName = \"tweets.txt\"\n",
    "fName1 = \"tweets1.txt\"\n",
    "simplified_result = twitter_api.search(q=\"Equity Bank\",since=start_date)\n",
    "with open(fName1,'w') as f:\n",
    "    for tweet in simplified_result:\n",
    "        f.write(jsonpickle.encode(tweet._json,unpicklable=False)+\"Equity Bank\"+\n",
    "                '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(simplified_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "TweepError",
     "evalue": "Twitter error response: status code = 429",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTweepError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-a78e65ba1fc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# apply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0msearch_and_extract_data_from_bank_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbanks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;31m# print(total_results)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-a78e65ba1fc9>\u001b[0m in \u001b[0;36msearch_and_extract_data_from_bank_tweets\u001b[0;34m(search_list)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# add the results to a json object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msearch_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 f.write(jsonpickle.encode(tweet._json,unpicklable=False)+\n\u001b[1;32m     35\u001b[0m                         '\\n')\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__self__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;31m# Parse the response payload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTweepError\u001b[0m: Twitter error response: status code = 429"
     ]
    }
   ],
   "source": [
    "\n",
    "# define file to save tweets\n",
    "filename = \"tweets.txt\"\n",
    "\n",
    "# create list of top banks\n",
    "banks_list = [\"KCB Bank\",\"Equity Bank\",\"Cooperative Bank\",\"Family Bank\",\n",
    "              \"DTB Bank\",\"Barclays Bank\",\"Standard Chartered Bank\",\"National Bank\",\"NCBA Bank\"]\n",
    "# search_text  = ['bank in kenya']\n",
    "\n",
    "# define start date\n",
    "start_date = \"2020-01-01\"\n",
    "\n",
    "# counter for search results\n",
    "total_results = 0\n",
    "\n",
    "# extract data for the selected banks\n",
    "def search_and_extract_data_from_bank_tweets(search_list):\n",
    "    \"\"\"\n",
    "    Takes a list of banks to query\n",
    "    \"\"\"\n",
    "    # create tweets dict\n",
    "#     tweets_dict = {'location':[],'bank_name':[],'date':[],'user':[],'text':[]}\n",
    "    \n",
    "    total_results = 0\n",
    "    \n",
    "    # open a file to write data\n",
    "    with open(filename,'w') as f:\n",
    "        \n",
    "        # search tweet for banks in the list\n",
    "        for i in search_list:\n",
    "            search_result = tweepy.Cursor(twitter_api.search,q=i,since=start_date).items()\n",
    "        \n",
    "            # add the results to a json object\n",
    "            for tweet in search_result:\n",
    "                f.write(jsonpickle.encode(tweet._json,unpicklable=False)+\n",
    "                        '\\n')\n",
    "                total_results+=1\n",
    "                \n",
    "        f.close()\n",
    "\n",
    "# apply\n",
    "search_and_extract_data_from_bank_tweets(banks_list)\n",
    "# print(total_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note\n",
    "Running above code we get a timeout error\n",
    "We need to optimize the search function so that we get as many tweets as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>entities</th>\n",
       "      <th>metadata</th>\n",
       "      <th>source</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>lang</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Aug 09 13:48:45 +0000 2020</td>\n",
       "      <td>1292457794990411777</td>\n",
       "      <td>1292457794990411777</td>\n",
       "      <td>Job Opportunity at KCB Bank Tanzania Limited -...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://www.drmasawe.info\" rel=\"nofol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Aug 09 13:46:33 +0000 2020</td>\n",
       "      <td>1292457240813686785</td>\n",
       "      <td>1292457240813686785</td>\n",
       "      <td>Job Opportunity at KCB Bank Tanzania Limited -...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://dlvrit.com/\" rel=\"nofollow\"&gt;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>{'media': [{'id': 1292457239312097287, 'id_str...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Aug 09 13:41:10 +0000 2020</td>\n",
       "      <td>1292455887139938304</td>\n",
       "      <td>1292455887139938304</td>\n",
       "      <td>Job Opportunity at KCB Bank Tanzania Limited â€“...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://publicize.wp.com/\" rel=\"nofoll...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Aug 09 13:38:33 +0000 2020</td>\n",
       "      <td>1292455227614875662</td>\n",
       "      <td>1292455227614875662</td>\n",
       "      <td>Job Opportunity at KCB Bank Tanzania Limited -...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://dlvrit.com/\" rel=\"nofollow\"&gt;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>{'media': [{'id': 1292455226067185664, 'id_str...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Aug 09 10:11:28 +0000 2020</td>\n",
       "      <td>1292403112393809921</td>\n",
       "      <td>1292403112393809921</td>\n",
       "      <td>New Job Vacancy at KCB Bank Tanzania Limited â€“...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://publicize.wp.com/\" rel=\"nofoll...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at                   id               id_str  \\\n",
       "0  Sun Aug 09 13:48:45 +0000 2020  1292457794990411777  1292457794990411777   \n",
       "1  Sun Aug 09 13:46:33 +0000 2020  1292457240813686785  1292457240813686785   \n",
       "2  Sun Aug 09 13:41:10 +0000 2020  1292455887139938304  1292455887139938304   \n",
       "3  Sun Aug 09 13:38:33 +0000 2020  1292455227614875662  1292455227614875662   \n",
       "4  Sun Aug 09 10:11:28 +0000 2020  1292403112393809921  1292403112393809921   \n",
       "\n",
       "                                                text  truncated  \\\n",
       "0  Job Opportunity at KCB Bank Tanzania Limited -...      False   \n",
       "1  Job Opportunity at KCB Bank Tanzania Limited -...      False   \n",
       "2  Job Opportunity at KCB Bank Tanzania Limited â€“...      False   \n",
       "3  Job Opportunity at KCB Bank Tanzania Limited -...      False   \n",
       "4  New Job Vacancy at KCB Bank Tanzania Limited â€“...      False   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "1  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "2  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "3  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "4  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "1  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "2  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "3  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "4  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "\n",
       "                                              source  in_reply_to_status_id  \\\n",
       "0  <a href=\"https://www.drmasawe.info\" rel=\"nofol...                    NaN   \n",
       "1  <a href=\"https://dlvrit.com/\" rel=\"nofollow\">d...                    NaN   \n",
       "2  <a href=\"http://publicize.wp.com/\" rel=\"nofoll...                    NaN   \n",
       "3  <a href=\"https://dlvrit.com/\" rel=\"nofollow\">d...                    NaN   \n",
       "4  <a href=\"http://publicize.wp.com/\" rel=\"nofoll...                    NaN   \n",
       "\n",
       "  in_reply_to_status_id_str  ...  favorite_count favorited retweeted  \\\n",
       "0                      None  ...               1     False     False   \n",
       "1                      None  ...               0     False     False   \n",
       "2                      None  ...               0     False     False   \n",
       "3                      None  ...               0     False     False   \n",
       "4                      None  ...               0     False     False   \n",
       "\n",
       "  possibly_sensitive lang                                  extended_entities  \\\n",
       "0              False   en                                                NaN   \n",
       "1              False   en  {'media': [{'id': 1292457239312097287, 'id_str...   \n",
       "2              False   en                                                NaN   \n",
       "3              False   en  {'media': [{'id': 1292455226067185664, 'id_str...   \n",
       "4              False   en                                                NaN   \n",
       "\n",
       "  retweeted_status quoted_status_id  quoted_status_id_str  quoted_status  \n",
       "0              NaN              NaN                   NaN            NaN  \n",
       "1              NaN              NaN                   NaN            NaN  \n",
       "2              NaN              NaN                   NaN            NaN  \n",
       "3              NaN              NaN                   NaN            NaN  \n",
       "4              NaN              NaN                   NaN            NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from saved file\n",
    "import json\n",
    "json_data = []\n",
    "with open(filename,'r') as f:\n",
    "    for line in f:\n",
    "        json_data.append(json.loads(line))\n",
    "        \n",
    "    f.close()\n",
    "\n",
    "# convert json file to dataframe\n",
    "bank_comments_df = pd.DataFrame(json_data)\n",
    "bank_comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add bank names column\n",
    "bank_comments_df['bank_name'] = np.where(bank_comments_df['text'].str.contains('Equity Bank',case=False),\"Equity Bank\",'')\n",
    "bank_comments_df['bank_name'] = np.where(bank_comments_df['text'].str.contains('KCB',case=False),\"KCB Bank\",bank_comments_df['bank_name'])\n",
    "bank_comments_df['bank_name'] = np.where(bank_comments_df['text'].str.contains('Cooperative Bank',case=False),\"Cooperative Bank\",bank_comments_df['bank_name'])\n",
    "bank_comments_df['bank_name'] = np.where(bank_comments_df['text'].str.contains('Family Bank',case=False),\"Family Bank\",bank_comments_df['bank_name'])\n",
    "bank_comments_df['bank_name'] = np.where(bank_comments_df['text'].str.contains('DTB Bank',case=False),\"DTB Bank\",bank_comments_df['bank_name'])\n",
    "bank_comments_df['bank_name'] = np.where(bank_comments_df['text'].str.contains('Barclays Bank',case=False),\"Barclays Bank\",bank_comments_df['bank_name'])\n",
    "bank_comments_df['bank_name'] = np.where(bank_comments_df['text'].str.contains('Standard Chartered Bank',case=False),\"Standard Chartered\",bank_comments_df['bank_name'])\n",
    "bank_comments_df['bank_name'] = np.where(bank_comments_df['text'].str.contains('NCBA Bank',case=False),\"NCBA Bank\",bank_comments_df['bank_name'])\n",
    "bank_comments_df['bank_name'] = np.where(bank_comments_df['text'].str.contains('National Bank',case=False),\"National Bank\",bank_comments_df['bank_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barclays Bank</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cooperative Bank</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Equity Bank</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KCB Bank</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>National Bank</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Standard Chartered</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bank_name    id\n",
       "0                      1878\n",
       "1       Barclays Bank     1\n",
       "2    Cooperative Bank    28\n",
       "3         Equity Bank   492\n",
       "4            KCB Bank   219\n",
       "5       National Bank     2\n",
       "6  Standard Chartered     2"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize twitter comments by bank\n",
    "bank_comments_df.groupby('bank_name')['id'].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Equity bank has the highest number of tweets followed by KCB Bank\n",
    "- We have a lot of comments that are not tied to any of out top banks\n",
    "- We should also optimize the search criteria to weed out some of these tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at Equity bank\n",
    "equity_bank_comment_df = bank_comments_df[bank_comments_df['bank_name']=='Equity Bank']\n",
    "equity_bank_comments = [x for x in equity_bank_comment_df['text'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['history', 'reminds', 'm', 'â€¦', 'rt', ':', 'thank', 'visiting', 'mama', 'lucy', 'equity', 'bank', 'team', '.', '\\n\\n', 'greatly', 'appreciate', 'support', 'ppes', 'hospital', 'â€¦', 'finance', 'master', ',', 'ceo', 'equity', 'bank', ',', 'championed', 'wings', 'fly', ',', 'james', 'man', '!', '!', 'equity', 'bank', ',', 'navigating', 'tough', 'tech', 'terrain', ',', 'innovating', 'customers', ' ', 'rt', ':', 'equity', 'bank', 'retain', 'pro', '-', 'people', 'focus', '?', 'stand', 'ordinary', 'people', 'built', '?', 'billion', 'dolla', 'â€¦', 'hi', 'jimmyn', ',', 'contact', 'equity', 'bank', '0202262000', '(', 'chargeable', ')', 'assistance', '.', '^ri', 'rt', '_']\n"
     ]
    }
   ],
   "source": [
    "# Using spacy we can tokenize tweet comments\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import re\n",
    "\n",
    "# get stop words\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "spacy_nlp = English()\n",
    "\n",
    "# remove usernames & links from tweets\n",
    "username_pattern = re.compile('^@[A-Za-z0-9_]{1,15}$')\n",
    "url_pattern = re.compile(r'^https?:\\/\\/.*[\\r\\n]*')\n",
    "\n",
    "# create tokens dictionary\n",
    "results = []\n",
    "for i in equity_bank_comments:\n",
    "    sentence_token = spacy_nlp(i)\n",
    "    token_result = []\n",
    "    for token in sentence_token:\n",
    "\n",
    "        # check if token is stop word\n",
    "        if token.is_stop == False:\n",
    "            token_result.append(token)\n",
    "\n",
    "    results.append(token_result)\n",
    "\n",
    "# clean results\n",
    "# remove usernames\n",
    "cleaned_results = []\n",
    "for x in results:\n",
    "    for i in x:\n",
    "        if (username_pattern.match(i.text) or url_pattern.match(i.text)):  \n",
    "            pass\n",
    "        else:\n",
    "            cleaned_results.append(str.lower(i.text))\n",
    "print(cleaned_results[100:180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lemmatize results\n",
    "# for word in cleaned_results[210:220]:\n",
    "#     print(word,word.lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>equity</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mwangi</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>james</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ceo</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dr</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>banks</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kenya</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>best</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>thepeoplesbanker</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>customers</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>financial</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mpesa</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>like</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>account</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>people</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>foundation</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pay</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>m</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  freq\n",
       "0               bank   278\n",
       "1             equity   255\n",
       "2                 rt    67\n",
       "3             mwangi    43\n",
       "4              james    42\n",
       "5                ceo    31\n",
       "6                 dr    31\n",
       "7              banks    18\n",
       "8              kenya    16\n",
       "9               best    16\n",
       "10  thepeoplesbanker    16\n",
       "11         customers    13\n",
       "12         financial    13\n",
       "13             mpesa    12\n",
       "14              like    10\n",
       "15           account    10\n",
       "16            people     9\n",
       "17        foundation     8\n",
       "18               pay     8\n",
       "19                 m     8"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create word frequency\n",
    "from string import punctuation\n",
    "# add some words to punctuation\n",
    "punctuation = punctuation + '\\n'+'â€¦'+'\\n\\n'+'RT'+' '+'..'+'...'\n",
    "word_frequencies = {}\n",
    "for word in cleaned_results:\n",
    "    if word not in punctuation:\n",
    "        if word not in word_frequencies.keys():\n",
    "            word_frequencies[word] = 1\n",
    "        else:\n",
    "            word_frequencies[word]+=1\n",
    "\n",
    "#  â€¦\t          \n",
    "word_freq_df = pd.DataFrame(word_frequencies.items(),columns = ['word','freq'])\n",
    "word_freq_df = word_freq_df.sort_values(by='freq',ascending=False).reset_index(drop=True)\n",
    "word_freq_df[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the word frequency, we do not see any major outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "\n",
      "We greatly appreciate the support with PPEs to the hospitalâ€¦, The finance master, CEO equity Bank, championed wings to Fly, James a man!!, https://t.co/OZh0CMsH0e, Equity Bank, Navigating Tough Tech Terrain, Innovating for Customers  https://t.co/s49008J4UR]\n"
     ]
    }
   ],
   "source": [
    "# create sentence tokenizer\n",
    "sbd = spacy_nlp.create_pipe('sentencizer')\n",
    "\n",
    "# add to pipeline\n",
    "spacy_nlp.add_pipe(sbd)\n",
    "\n",
    "# create spacy doc\n",
    "sentence_list = []\n",
    "for tweet in equity_bank_comments:\n",
    "    tweet_doc = spacy_nlp(tweet)\n",
    "    for sentence in tweet_doc.sents:\n",
    "        sentence_list.append(sentence)\n",
    "    \n",
    "# print sentence list\n",
    "print(sentence_list[16:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
